// Generated by ScalaBuff, the Scala Protocol Buffers compiler. DO NOT EDIT!
// source: message.proto
// $COVERAGE-OFF$Disabling coverage for generated sources

package com.mozilla.telemetry.heka

final case class Header (
	messageLength: Int = 0,
	hmacHashFunction: Option[Header.HmacHashFunction.EnumVal] = Some(Header.HmacHashFunction.MD5),
	hmacSigner: Option[String] = None,
	hmacKeyVersion: Option[Int] = None,
	hmac: Option[com.google.protobuf.ByteString] = None
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Header]
	with net.sandrogrzicic.scalabuff.Parser[Header] {

	def setHmacHashFunction(_f: Header.HmacHashFunction.EnumVal) = copy(hmacHashFunction = Some(_f))
	def setHmacSigner(_f: String) = copy(hmacSigner = Some(_f))
	def setHmacKeyVersion(_f: Int) = copy(hmacKeyVersion = Some(_f))
	def setHmac(_f: com.google.protobuf.ByteString) = copy(hmac = Some(_f))

	def clearHmacHashFunction = copy(hmacHashFunction = None)
	def clearHmacSigner = copy(hmacSigner = None)
	def clearHmacKeyVersion = copy(hmacKeyVersion = None)
	def clearHmac = copy(hmac = None)

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		output.writeUInt32(1, messageLength)
		if (hmacHashFunction.isDefined) output.writeEnum(3, hmacHashFunction.get)
		if (hmacSigner.isDefined) output.writeString(4, hmacSigner.get)
		if (hmacKeyVersion.isDefined) output.writeUInt32(5, hmacKeyVersion.get)
		if (hmac.isDefined) output.writeBytes(6, hmac.get)
	}

	def getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var __size = 0
		__size += computeUInt32Size(1, messageLength)
		if (hmacHashFunction.isDefined) __size += computeEnumSize(3, hmacHashFunction.get)
		if (hmacSigner.isDefined) __size += computeStringSize(4, hmacSigner.get)
		if (hmacKeyVersion.isDefined) __size += computeUInt32Size(5, hmacKeyVersion.get)
		if (hmac.isDefined) __size += computeBytesSize(6, hmac.get)

		__size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Header = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __messageLength: Int = 0
		var __hmacHashFunction: Option[Header.HmacHashFunction.EnumVal] = hmacHashFunction
		var __hmacSigner: Option[String] = hmacSigner
		var __hmacKeyVersion: Option[Int] = hmacKeyVersion
		var __hmac: Option[com.google.protobuf.ByteString] = hmac

		def __newMerged = Header(
			__messageLength,
			__hmacHashFunction,
			__hmacSigner,
			__hmacKeyVersion,
			__hmac
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 8 => __messageLength = in.readUInt32()
			case 24 => __hmacHashFunction = Some(try { Header.HmacHashFunction.valueOf(in.readEnum()) } catch { case e: Exception => Some(Header.HmacHashFunction.MD5).get })
			case 34 => __hmacSigner = Some(in.readString())
			case 40 => __hmacKeyVersion = Some(in.readUInt32())
			case 50 => __hmac = Some(in.readBytes())
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Header) = {
		Header(
			m.messageLength,
			m.hmacHashFunction.orElse(hmacHashFunction),
			m.hmacSigner.orElse(hmacSigner),
			m.hmacKeyVersion.orElse(hmacKeyVersion),
			m.hmac.orElse(hmac)
		)
	}

	def getDefaultInstanceForType = Header.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
	override def getParserForType = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
	def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Header {
	@scala.beans.BeanProperty val defaultInstance = new Header()

	def parseFrom(data: Array[Byte]): Header = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Header = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Header = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Header = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Header] = defaultInstance.mergeDelimitedFromStream(stream)

	val MESSAGE_LENGTH_FIELD_NUMBER = 1
	val HMAC_HASH_FUNCTION_FIELD_NUMBER = 3
	val HMAC_SIGNER_FIELD_NUMBER = 4
	val HMAC_KEY_VERSION_FIELD_NUMBER = 5
	val HMAC_FIELD_NUMBER = 6

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Header) = defaultInstance.mergeFrom(prototype)

	object HmacHashFunction extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val MD5 = new EnumVal { val name = "MD5"; val id = 0 }
		val SHA1 = new EnumVal { val name = "SHA1"; val id = 1 }

		val MD5_VALUE = 0
		val SHA1_VALUE = 1

		def valueOf(id: Int) = id match {
			case 0 => MD5
			case 1 => SHA1
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

}
final case class Field (
	name: String = "",
	valueType: Option[Field.ValueType.EnumVal] = Some(Field.ValueType.STRING),
	representation: Option[String] = None,
	valueString: scala.collection.immutable.Seq[String] = Vector.empty[String],
	valueBytes: scala.collection.immutable.Seq[com.google.protobuf.ByteString] = Vector.empty[com.google.protobuf.ByteString],
	valueInteger: scala.collection.immutable.Seq[Long] = Vector.empty[Long],
	valueDouble: scala.collection.immutable.Seq[Double] = Vector.empty[Double],
	valueBool: scala.collection.immutable.Seq[Boolean] = Vector.empty[Boolean]
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Field]
	with net.sandrogrzicic.scalabuff.Parser[Field] {

	def setValueType(_f: Field.ValueType.EnumVal) = copy(valueType = Some(_f))
	def setRepresentation(_f: String) = copy(representation = Some(_f))
	def setValueString(_i: Int, _v: String) = copy(valueString = valueString.updated(_i, _v))
	def addValueString(_f: String) = copy(valueString = valueString :+ _f)
	def addAllValueString(_f: String*) = copy(valueString = valueString ++ _f)
	def addAllValueString(_f: TraversableOnce[String]) = copy(valueString = valueString ++ _f)
	def setValueBytes(_i: Int, _v: com.google.protobuf.ByteString) = copy(valueBytes = valueBytes.updated(_i, _v))
	def addValueBytes(_f: com.google.protobuf.ByteString) = copy(valueBytes = valueBytes :+ _f)
	def addAllValueBytes(_f: com.google.protobuf.ByteString*) = copy(valueBytes = valueBytes ++ _f)
	def addAllValueBytes(_f: TraversableOnce[com.google.protobuf.ByteString]) = copy(valueBytes = valueBytes ++ _f)
	def setValueInteger(_i: Int, _v: Long) = copy(valueInteger = valueInteger.updated(_i, _v))
	def addValueInteger(_f: Long) = copy(valueInteger = valueInteger :+ _f)
	def addAllValueInteger(_f: Long*) = copy(valueInteger = valueInteger ++ _f)
	def addAllValueInteger(_f: TraversableOnce[Long]) = copy(valueInteger = valueInteger ++ _f)
	def setValueDouble(_i: Int, _v: Double) = copy(valueDouble = valueDouble.updated(_i, _v))
	def addValueDouble(_f: Double) = copy(valueDouble = valueDouble :+ _f)
	def addAllValueDouble(_f: Double*) = copy(valueDouble = valueDouble ++ _f)
	def addAllValueDouble(_f: TraversableOnce[Double]) = copy(valueDouble = valueDouble ++ _f)
	def setValueBool(_i: Int, _v: Boolean) = copy(valueBool = valueBool.updated(_i, _v))
	def addValueBool(_f: Boolean) = copy(valueBool = valueBool :+ _f)
	def addAllValueBool(_f: Boolean*) = copy(valueBool = valueBool ++ _f)
	def addAllValueBool(_f: TraversableOnce[Boolean]) = copy(valueBool = valueBool ++ _f)

	def clearValueType = copy(valueType = None)
	def clearRepresentation = copy(representation = None)
	def clearValueString = copy(valueString = Vector.empty[String])
	def clearValueBytes = copy(valueBytes = Vector.empty[com.google.protobuf.ByteString])
	def clearValueInteger = copy(valueInteger = Vector.empty[Long])
	def clearValueDouble = copy(valueDouble = Vector.empty[Double])
	def clearValueBool = copy(valueBool = Vector.empty[Boolean])

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		output.writeString(1, name)
		if (valueType.isDefined) output.writeEnum(2, valueType.get)
		if (representation.isDefined) output.writeString(3, representation.get)
		for (_v <- valueString) output.writeString(4, _v)
		for (_v <- valueBytes) output.writeBytes(5, _v)
		// write field value_integer packed 
		if (!valueInteger.isEmpty) {
			import com.google.protobuf.CodedOutputStream._
			val dataSize = valueInteger.map(computeInt64SizeNoTag(_)).sum 
			output.writeRawVarint32(50)
			output.writeRawVarint32(dataSize)
			for (_v <- valueInteger) output.writeInt64NoTag(_v)
		}
		// write field value_double packed 
		if (!valueDouble.isEmpty) {
			import com.google.protobuf.CodedOutputStream._
			val dataSize = valueDouble.map(computeDoubleSizeNoTag(_)).sum 
			output.writeRawVarint32(58)
			output.writeRawVarint32(dataSize)
			for (_v <- valueDouble) output.writeDoubleNoTag(_v)
		}
		// write field value_bool packed 
		if (!valueBool.isEmpty) {
			import com.google.protobuf.CodedOutputStream._
			val dataSize = valueBool.map(computeBoolSizeNoTag(_)).sum 
			output.writeRawVarint32(66)
			output.writeRawVarint32(dataSize)
			for (_v <- valueBool) output.writeBoolNoTag(_v)
		}
	}

	def getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var __size = 0
		__size += computeStringSize(1, name)
		if (valueType.isDefined) __size += computeEnumSize(2, valueType.get)
		if (representation.isDefined) __size += computeStringSize(3, representation.get)
		for (_v <- valueString) __size += computeStringSize(4, _v)
		for (_v <- valueBytes) __size += computeBytesSize(5, _v)
		if (!valueInteger.isEmpty) {
			val dataSize = valueInteger.map(computeInt64SizeNoTag(_)).sum 
			__size += 1 + computeInt32SizeNoTag(dataSize) + dataSize
		}
		if (!valueDouble.isEmpty) {
			val dataSize = valueDouble.map(computeDoubleSizeNoTag(_)).sum 
			__size += 1 + computeInt32SizeNoTag(dataSize) + dataSize
		}
		if (!valueBool.isEmpty) {
			val dataSize = valueBool.map(computeBoolSizeNoTag(_)).sum 
			__size += 1 + computeInt32SizeNoTag(dataSize) + dataSize
		}

		__size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Field = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __name: String = ""
		var __valueType: Option[Field.ValueType.EnumVal] = valueType
		var __representation: Option[String] = representation
		val __valueString: scala.collection.mutable.Buffer[String] = valueString.toBuffer
		val __valueBytes: scala.collection.mutable.Buffer[com.google.protobuf.ByteString] = valueBytes.toBuffer
		val __valueInteger: scala.collection.mutable.Buffer[Long] = valueInteger.toBuffer
		val __valueDouble: scala.collection.mutable.Buffer[Double] = valueDouble.toBuffer
		val __valueBool: scala.collection.mutable.Buffer[Boolean] = valueBool.toBuffer

		def __newMerged = Field(
			__name,
			__valueType,
			__representation,
			Vector(__valueString: _*),
			Vector(__valueBytes: _*),
			Vector(__valueInteger: _*),
			Vector(__valueDouble: _*),
			Vector(__valueBool: _*)
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 10 => __name = in.readString()
			case 16 => __valueType = Some(try { Field.ValueType.valueOf(in.readEnum()) } catch { case e: Exception => Some(Field.ValueType.STRING).get })
			case 26 => __representation = Some(in.readString())
			case 34 => __valueString += in.readString()
			case 42 => __valueBytes += in.readBytes()
			case 48 => __valueInteger += in.readInt64()
			case 50 => 
				val length = in.readRawVarint32()
				val limit = in.pushLimit(length)
				while (in.getBytesUntilLimit() > 0) {
					__valueInteger += in.readInt64()
				}
				in.popLimit(limit)
			case 57 => __valueDouble += in.readDouble()
			case 58 => 
				val length = in.readRawVarint32()
				val limit = in.pushLimit(length)
				while (in.getBytesUntilLimit() > 0) {
					__valueDouble += in.readDouble()
				}
				in.popLimit(limit)
			case 64 => __valueBool += in.readBool()
			case 66 => 
				val length = in.readRawVarint32()
				val limit = in.pushLimit(length)
				while (in.getBytesUntilLimit() > 0) {
					__valueBool += in.readBool()
				}
				in.popLimit(limit)
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Field) = {
		Field(
			m.name,
			m.valueType.orElse(valueType),
			m.representation.orElse(representation),
			valueString ++ m.valueString,
			valueBytes ++ m.valueBytes,
			valueInteger ++ m.valueInteger,
			valueDouble ++ m.valueDouble,
			valueBool ++ m.valueBool
		)
	}

	def getDefaultInstanceForType = Field.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
	override def getParserForType = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
	def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Field {
	@scala.beans.BeanProperty val defaultInstance = new Field()

	def parseFrom(data: Array[Byte]): Field = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Field = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Field = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Field = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Field] = defaultInstance.mergeDelimitedFromStream(stream)

	val NAME_FIELD_NUMBER = 1
	val VALUE_TYPE_FIELD_NUMBER = 2
	val REPRESENTATION_FIELD_NUMBER = 3
	val VALUE_STRING_FIELD_NUMBER = 4
	val VALUE_BYTES_FIELD_NUMBER = 5
	val VALUE_INTEGER_FIELD_NUMBER = 6
	val VALUE_DOUBLE_FIELD_NUMBER = 7
	val VALUE_BOOL_FIELD_NUMBER = 8

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Field) = defaultInstance.mergeFrom(prototype)

	object ValueType extends net.sandrogrzicic.scalabuff.Enum {
		sealed trait EnumVal extends Value
		val _UNINITIALIZED = new EnumVal { val name = "UNINITIALIZED ENUM VALUE"; val id = -1 }

		val STRING = new EnumVal { val name = "STRING"; val id = 0 }
		val BYTES = new EnumVal { val name = "BYTES"; val id = 1 }
		val INTEGER = new EnumVal { val name = "INTEGER"; val id = 2 }
		val DOUBLE = new EnumVal { val name = "DOUBLE"; val id = 3 }
		val BOOL = new EnumVal { val name = "BOOL"; val id = 4 }

		val STRING_VALUE = 0
		val BYTES_VALUE = 1
		val INTEGER_VALUE = 2
		val DOUBLE_VALUE = 3
		val BOOL_VALUE = 4

		def valueOf(id: Int) = id match {
			case 0 => STRING
			case 1 => BYTES
			case 2 => INTEGER
			case 3 => DOUBLE
			case 4 => BOOL
			case _default => throw new net.sandrogrzicic.scalabuff.UnknownEnumException(_default)
		}
		val internalGetValueMap = new com.google.protobuf.Internal.EnumLiteMap[EnumVal] {
			def findValueByNumber(id: Int): EnumVal = valueOf(id)
		}
	}

}
final case class Message (
	uuid: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY,
	timestamp: Long = 0L,
	`type`: Option[String] = None,
	logger: Option[String] = None,
	severity: Option[Int] = Some(7),
	payload: Option[String] = None,
	envVersion: Option[String] = None,
	pid: Option[Int] = None,
	hostname: Option[String] = None,
	fields: scala.collection.immutable.Seq[Field] = Vector.empty[Field]
) extends com.google.protobuf.GeneratedMessageLite
	with com.google.protobuf.MessageLite.Builder
	with net.sandrogrzicic.scalabuff.Message[Message]
	with net.sandrogrzicic.scalabuff.Parser[Message] {

	def setType(_f: String) = copy(`type` = Some(_f))
	def setLogger(_f: String) = copy(logger = Some(_f))
	def setSeverity(_f: Int) = copy(severity = Some(_f))
	def setPayload(_f: String) = copy(payload = Some(_f))
	def setEnvVersion(_f: String) = copy(envVersion = Some(_f))
	def setPid(_f: Int) = copy(pid = Some(_f))
	def setHostname(_f: String) = copy(hostname = Some(_f))
	def setFields(_i: Int, _v: Field) = copy(fields = fields.updated(_i, _v))
	def addFields(_f: Field) = copy(fields = fields :+ _f)
	def addAllFields(_f: Field*) = copy(fields = fields ++ _f)
	def addAllFields(_f: TraversableOnce[Field]) = copy(fields = fields ++ _f)

	def clearType = copy(`type` = None)
	def clearLogger = copy(logger = None)
	def clearSeverity = copy(severity = None)
	def clearPayload = copy(payload = None)
	def clearEnvVersion = copy(envVersion = None)
	def clearPid = copy(pid = None)
	def clearHostname = copy(hostname = None)
	def clearFields = copy(fields = Vector.empty[Field])

	def writeTo(output: com.google.protobuf.CodedOutputStream) {
		output.writeBytes(1, uuid)
		output.writeInt64(2, timestamp)
		if (`type`.isDefined) output.writeString(3, `type`.get)
		if (logger.isDefined) output.writeString(4, logger.get)
		if (severity.isDefined) output.writeInt32(5, severity.get)
		if (payload.isDefined) output.writeString(6, payload.get)
		if (envVersion.isDefined) output.writeString(7, envVersion.get)
		if (pid.isDefined) output.writeInt32(8, pid.get)
		if (hostname.isDefined) output.writeString(9, hostname.get)
		for (_v <- fields) output.writeMessage(10, _v)
	}

	def getSerializedSize = {
		import com.google.protobuf.CodedOutputStream._
		var __size = 0
		__size += computeBytesSize(1, uuid)
		__size += computeInt64Size(2, timestamp)
		if (`type`.isDefined) __size += computeStringSize(3, `type`.get)
		if (logger.isDefined) __size += computeStringSize(4, logger.get)
		if (severity.isDefined) __size += computeInt32Size(5, severity.get)
		if (payload.isDefined) __size += computeStringSize(6, payload.get)
		if (envVersion.isDefined) __size += computeStringSize(7, envVersion.get)
		if (pid.isDefined) __size += computeInt32Size(8, pid.get)
		if (hostname.isDefined) __size += computeStringSize(9, hostname.get)
		for (_v <- fields) __size += computeMessageSize(10, _v)

		__size
	}

	def mergeFrom(in: com.google.protobuf.CodedInputStream, extensionRegistry: com.google.protobuf.ExtensionRegistryLite): Message = {
		import com.google.protobuf.ExtensionRegistryLite.{getEmptyRegistry => _emptyRegistry}
		var __uuid: com.google.protobuf.ByteString = com.google.protobuf.ByteString.EMPTY
		var __timestamp: Long = 0L
		var __type: Option[String] = `type`
		var __logger: Option[String] = logger
		var __severity: Option[Int] = severity
		var __payload: Option[String] = payload
		var __envVersion: Option[String] = envVersion
		var __pid: Option[Int] = pid
		var __hostname: Option[String] = hostname
		val __fields: scala.collection.mutable.Buffer[Field] = fields.toBuffer

		def __newMerged = Message(
			__uuid,
			__timestamp,
			__type,
			__logger,
			__severity,
			__payload,
			__envVersion,
			__pid,
			__hostname,
			Vector(__fields: _*)
		)
		while (true) in.readTag match {
			case 0 => return __newMerged
			case 10 => __uuid = in.readBytes()
			case 16 => __timestamp = in.readInt64()
			case 26 => __type = Some(in.readString())
			case 34 => __logger = Some(in.readString())
			case 40 => __severity = Some(in.readInt32())
			case 50 => __payload = Some(in.readString())
			case 58 => __envVersion = Some(in.readString())
			case 64 => __pid = Some(in.readInt32())
			case 74 => __hostname = Some(in.readString())
			case 82 => __fields += readMessage[Field](in, Field.defaultInstance, _emptyRegistry)
			case default => if (!in.skipField(default)) return __newMerged
		}
		null
	}

	def mergeFrom(m: Message) = {
		Message(
			m.uuid,
			m.timestamp,
			m.`type`.orElse(`type`),
			m.logger.orElse(logger),
			m.severity.orElse(severity),
			m.payload.orElse(payload),
			m.envVersion.orElse(envVersion),
			m.pid.orElse(pid),
			m.hostname.orElse(hostname),
			fields ++ m.fields
		)
	}

	def getDefaultInstanceForType = Message.defaultInstance
	def clear = getDefaultInstanceForType
	def isInitialized = true
	def build = this
	def buildPartial = this
	def parsePartialFrom(cis: com.google.protobuf.CodedInputStream, er: com.google.protobuf.ExtensionRegistryLite) = mergeFrom(cis, er)
	override def getParserForType = this
	def newBuilderForType = getDefaultInstanceForType
	def toBuilder = this
	def toJson(indent: Int = 0): String = "ScalaBuff JSON generation not enabled. Use --generate_json_method to enable."
}

object Message {
	@scala.beans.BeanProperty val defaultInstance = new Message()

	def parseFrom(data: Array[Byte]): Message = defaultInstance.mergeFrom(data)
	def parseFrom(data: Array[Byte], offset: Int, length: Int): Message = defaultInstance.mergeFrom(data, offset, length)
	def parseFrom(byteString: com.google.protobuf.ByteString): Message = defaultInstance.mergeFrom(byteString)
	def parseFrom(stream: java.io.InputStream): Message = defaultInstance.mergeFrom(stream)
	def parseDelimitedFrom(stream: java.io.InputStream): Option[Message] = defaultInstance.mergeDelimitedFromStream(stream)

	val UUID_FIELD_NUMBER = 1
	val TIMESTAMP_FIELD_NUMBER = 2
	val TYPE_FIELD_NUMBER = 3
	val LOGGER_FIELD_NUMBER = 4
	val SEVERITY_FIELD_NUMBER = 5
	val PAYLOAD_FIELD_NUMBER = 6
	val ENV_VERSION_FIELD_NUMBER = 7
	val PID_FIELD_NUMBER = 8
	val HOSTNAME_FIELD_NUMBER = 9
	val FIELDS_FIELD_NUMBER = 10

	def newBuilder = defaultInstance.newBuilderForType
	def newBuilder(prototype: Message) = defaultInstance.mergeFrom(prototype)

}

object HekaMessage {
	def registerAllExtensions(registry: com.google.protobuf.ExtensionRegistryLite) {
	}

	private val fromBinaryHintMap = collection.immutable.HashMap[String, Array[Byte] ⇒ com.google.protobuf.GeneratedMessageLite](
		 "Header" -> (bytes ⇒ Header.parseFrom(bytes)),
		 "Field" -> (bytes ⇒ Field.parseFrom(bytes)),
		 "Message" -> (bytes ⇒ Message.parseFrom(bytes))
	)

	def deserializePayload(payload: Array[Byte], payloadType: String): com.google.protobuf.GeneratedMessageLite = {
		fromBinaryHintMap.get(payloadType) match {
			case Some(f) ⇒ f(payload)
			case None    ⇒ throw new IllegalArgumentException(s"unimplemented deserialization of message payload of type [${payloadType}]")
		}
	}
}
// $COVERAGE-ON$
